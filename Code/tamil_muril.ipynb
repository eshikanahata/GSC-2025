{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMK4TVe+nS+XqhI2cedlzqA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e66b65e568bd496caa3821282e6876bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c60efead8da644f8bd16acc1343caf8f","IPY_MODEL_501d7fca9d244881a4853c8329f0b29c","IPY_MODEL_e1bcbbcdb06947a893eceeb5d6d9685d"],"layout":"IPY_MODEL_f2b7f0ae2e2b4359931e87e7a2234d3d"}},"c60efead8da644f8bd16acc1343caf8f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_07ae700d0bd14bc09c73d23f2f0734b8","placeholder":"​","style":"IPY_MODEL_87dd03e18e0e474896fc179bffef5734","value":"Map: 100%"}},"501d7fca9d244881a4853c8329f0b29c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2e8cbf0bebb443a29505a5fdcfd2f80a","max":42452,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61d631a08b1347b286c4adc42c780028","value":42452}},"e1bcbbcdb06947a893eceeb5d6d9685d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a7142afa0124c4990c7f8cbc598ecbc","placeholder":"​","style":"IPY_MODEL_627208d38b634d63b404cde0ab69a3ae","value":" 42452/42452 [00:16&lt;00:00, 2894.73 examples/s]"}},"f2b7f0ae2e2b4359931e87e7a2234d3d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"07ae700d0bd14bc09c73d23f2f0734b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"87dd03e18e0e474896fc179bffef5734":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e8cbf0bebb443a29505a5fdcfd2f80a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61d631a08b1347b286c4adc42c780028":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a7142afa0124c4990c7f8cbc598ecbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"627208d38b634d63b404cde0ab69a3ae":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bb8fa1ce8b424594879ba842e141f2c4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_07464a051f5440a09e8f311397d6dfaf","IPY_MODEL_7736541f32104bba98b865caf2ba7c30","IPY_MODEL_e415b42f727745ebb527f0d9ef7eca71"],"layout":"IPY_MODEL_76515f7267c44077959ccfb75d0ffbae"}},"07464a051f5440a09e8f311397d6dfaf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0b8db292d8ab43e0beed19f2a59b2963","placeholder":"​","style":"IPY_MODEL_2c07e6f16f034f6195d8eb58e8326c7f","value":"Map: 100%"}},"7736541f32104bba98b865caf2ba7c30":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_03f17d3fe7e549eaa458ec66d7f6d466","max":6969,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b92eba7c0e424e02b1740ba9ced999ef","value":6969}},"e415b42f727745ebb527f0d9ef7eca71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ea5206d4cec4cc7ab2a17dcf398e315","placeholder":"​","style":"IPY_MODEL_3c897117f5ae40dca1f8f78cedbe8d08","value":" 6969/6969 [00:00&lt;00:00, 6877.46 examples/s]"}},"76515f7267c44077959ccfb75d0ffbae":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b8db292d8ab43e0beed19f2a59b2963":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c07e6f16f034f6195d8eb58e8326c7f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"03f17d3fe7e549eaa458ec66d7f6d466":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b92eba7c0e424e02b1740ba9ced999ef":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1ea5206d4cec4cc7ab2a17dcf398e315":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c897117f5ae40dca1f8f78cedbe8d08":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install transformers peft datasets torch evaluate"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"ZNvslyyJ5vl2","executionInfo":{"status":"ok","timestamp":1742115882728,"user_tz":-330,"elapsed":100036,"user":{"displayName":"Eshika Nahata da24b004","userId":"15594037933238871492"}},"outputId":"84d5adc8-f0fe-403d-9e75-5bc782d68e44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n","Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n","Collecting datasets\n","  Downloading datasets-3.4.0-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Collecting evaluate\n","  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.3.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n","Collecting dill<0.3.9,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess<0.70.17 (from datasets)\n","  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Downloading datasets-3.4.0-py3-none-any.whl (487 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m487.4/487.4 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, evaluate\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed datasets-3.4.0 dill-0.3.8 evaluate-0.4.3 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n","from peft import LoraConfig, get_peft_model, TaskType"],"metadata":{"id":"ctmGmH67JErM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = pd.read_csv('tamil_offensive_speech_train.csv', on_bad_lines='skip', encoding='utf-8')\n","print(\"Dataset loaded successfully:\")\n","print(train_data.head())\n","train_dataset = Dataset.from_pandas(train_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GqLDCI0KJDdj","executionInfo":{"status":"ok","timestamp":1742117605965,"user_tz":-330,"elapsed":116,"user":{"displayName":"Eshika Nahata da24b004","userId":"15594037933238871492"}},"outputId":"4381cefa-78b6-41c5-b627-75ff86a60b94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset loaded successfully:\n","   label                                            comment\n","0      0                  omg that bgm make me goosebumb...\n","1      0         neraya neraya neraya neraya neraya neraya.\n","2      0  thalaivar mersal look .semma massss thalaiva ....\n","3      0  paaaa... repeat mode.... adra adra adraaaaa......\n","4      0  epaa ena panaporam... sweet sapade poram... aw...\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from imblearn.over_sampling import RandomOverSampler\n","from collections import Counter\n","from datasets import Dataset\n","\n","# Extract features and labels\n","X_train = [example[\"comment\"] for example in train_dataset]\n","y_train = [example[\"label\"] for example in train_dataset]\n","\n","# Convert lists to NumPy arrays\n","X_train = np.array(X_train).reshape(-1, 1)  # Reshape to (n_samples, 1)\n","y_train = np.array(y_train)\n","\n","# Oversample minority class\n","ros = RandomOverSampler(sampling_strategy=\"auto\", random_state=42)\n","X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n","\n","# Convert back to Hugging Face Dataset\n","train_dataset = Dataset.from_dict({\n","    \"comment\": X_resampled.flatten().tolist(),  # Convert back to list of strings\n","    \"label\": y_resampled.tolist()\n","})\n","\n","# Check class distribution after oversampling\n","print(Counter(y_resampled))  # Should show balanced classes\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b2HhiVBEu-As","executionInfo":{"status":"ok","timestamp":1742117609041,"user_tz":-330,"elapsed":2205,"user":{"displayName":"Eshika Nahata da24b004","userId":"15594037933238871492"}},"outputId":"f0e6619f-cafe-40bf-cd2f-f36506738c58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({0: 21226, 1: 21226})\n"]}]},{"cell_type":"code","source":["val_data = pd.read_csv('tamil_offensive_speech_val.csv', on_bad_lines='skip', encoding='utf-8')\n","print(\"Dataset loaded successfully:\")\n","print(val_data.head())\n","val_dataset = Dataset.from_pandas(val_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nAOr8KODOmdK","executionInfo":{"status":"ok","timestamp":1742117609062,"user_tz":-330,"elapsed":20,"user":{"displayName":"Eshika Nahata da24b004","userId":"15594037933238871492"}},"outputId":"6c73dafc-867c-444c-b93a-2854e94e115d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset loaded successfully:\n","   label                                            comment\n","0      0  annan thambingalam poondhu vilayada poranga🤩🤩....\n","1      1                  ha ha ha ha appo naiya thebingala\n","2      0  manitha samuthaayam amaipil irunthu intha pada...\n","3      1  otha virundhalikku porandhavan tha jaadhi ah t...\n","4      1  ama padichavan vanda mattum vote potruvanungee...\n"]}]},{"cell_type":"code","source":["print(train_dataset[3])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m4DFfrd1NMWP","executionInfo":{"status":"ok","timestamp":1742117609081,"user_tz":-330,"elapsed":5,"user":{"displayName":"Eshika Nahata da24b004","userId":"15594037933238871492"}},"outputId":"b5047a3e-4bf9-453c-bf17-1eca79936519"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'comment': 'paaaa... repeat mode.... adra adra adraaaaa..... vera level... vare va....', 'label': 0}\n"]}]},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(\"google/muril-base-cased\")\n","\n","def tokenize_function(examples):\n","    comments = examples[\"comment\"]\n","\n","    # Ensure every comment is a string (convert None to an empty string)\n","    if isinstance(comments, list):\n","        comments = [c if isinstance(c, str) else \"\" for c in comments]\n","    else:\n","        comments = comments if isinstance(comments, str) else \"\"\n","\n","    return tokenizer(comments, padding='max_length', truncation=True, max_length=128)\n","\n","\n","\n","tamil_0_tokenized = train_dataset.map(tokenize_function, batched=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["e66b65e568bd496caa3821282e6876bd","c60efead8da644f8bd16acc1343caf8f","501d7fca9d244881a4853c8329f0b29c","e1bcbbcdb06947a893eceeb5d6d9685d","f2b7f0ae2e2b4359931e87e7a2234d3d","07ae700d0bd14bc09c73d23f2f0734b8","87dd03e18e0e474896fc179bffef5734","2e8cbf0bebb443a29505a5fdcfd2f80a","61d631a08b1347b286c4adc42c780028","7a7142afa0124c4990c7f8cbc598ecbc","627208d38b634d63b404cde0ab69a3ae"]},"id":"EHrIApxHN1Yn","executionInfo":{"status":"ok","timestamp":1742117627515,"user_tz":-330,"elapsed":18432,"user":{"displayName":"Eshika Nahata da24b004","userId":"15594037933238871492"}},"outputId":"2a14c297-ae86-443c-8f98-45a475609a03"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/42452 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e66b65e568bd496caa3821282e6876bd"}},"metadata":{}}]},{"cell_type":"code","source":["tamil_1_tokenized = val_dataset.map(tokenize_function, batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["bb8fa1ce8b424594879ba842e141f2c4","07464a051f5440a09e8f311397d6dfaf","7736541f32104bba98b865caf2ba7c30","e415b42f727745ebb527f0d9ef7eca71","76515f7267c44077959ccfb75d0ffbae","0b8db292d8ab43e0beed19f2a59b2963","2c07e6f16f034f6195d8eb58e8326c7f","03f17d3fe7e549eaa458ec66d7f6d466","b92eba7c0e424e02b1740ba9ced999ef","1ea5206d4cec4cc7ab2a17dcf398e315","3c897117f5ae40dca1f8f78cedbe8d08"]},"id":"rxKgy8wDlBhl","executionInfo":{"status":"ok","timestamp":1742117628567,"user_tz":-330,"elapsed":1051,"user":{"displayName":"Eshika Nahata da24b004","userId":"15594037933238871492"}},"outputId":"778eee15-806a-4bc5-a97c-4a5208c85859"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/6969 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb8fa1ce8b424594879ba842e141f2c4"}},"metadata":{}}]},{"cell_type":"code","source":["model = AutoModelForSequenceClassification.from_pretrained(\n","    \"google/muril-base-cased\",\n","    num_labels=2\n",")\n","\n","\n","lora_config = LoraConfig(\n","    task_type=TaskType.SEQ_CLS,\n","    r=16,\n","    lora_alpha=32,\n","    lora_dropout=0.1,\n","    target_modules=[\"query\", \"key\", \"value\"],\n","    bias=\"none\"\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SKBpaD5bN7va","executionInfo":{"status":"ok","timestamp":1742117628866,"user_tz":-330,"elapsed":298,"user":{"displayName":"Eshika Nahata da24b004","userId":"15594037933238871492"}},"outputId":"1128bc04-e793-4c5c-f385-396d233b31f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google/muril-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, f1_score\n","import numpy as np\n","import torch.nn as nn\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = np.argmax(logits, axis=1)\n","    acc = accuracy_score(labels, predictions)\n","    return {\"accuracy\": acc}"],"metadata":{"id":"pxe30GOanGZI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n","        \"\"\"\n","        alpha: Balancing factor for class imbalance (list or tensor).\n","        gamma: Focusing parameter (higher = more focus on hard examples).\n","        reduction: 'mean' or 'sum' (same as CrossEntropyLoss).\n","        \"\"\"\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.reduction = reduction\n","\n","    def forward(self, logits, targets):\n","        ce_loss = F.cross_entropy(logits, targets, reduction='none')  # Standard CE loss\n","        pt = torch.exp(-ce_loss)  # Probability of the true class\n","        focal_loss = (1 - pt) ** self.gamma * ce_loss  # Apply Focal Loss scaling\n","\n","        # Apply alpha weighting if provided\n","        if self.alpha is not None:\n","            alpha_t = self.alpha.gather(0, targets.view(-1))  # Get alpha for each label\n","            focal_loss *= alpha_t\n","\n","        # Reduction method\n","        if self.reduction == 'mean':\n","            return focal_loss.mean()\n","        elif self.reduction == 'sum':\n","            return focal_loss.sum()\n","        return focal_loss"],"metadata":{"id":"9igflLVN0BrQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels = np.array([example[\"label\"] for example in train_dataset])\n","class_counts = np.bincount(labels)\n","\n","class_weights = torch.tensor(1.0 / class_counts, dtype=torch.float).to(\"cuda\")\n","class_weights = class_weights / class_weights.sum()\n","loss_fn = FocalLoss(alpha=class_weights, gamma=2.0)"],"metadata":{"id":"ao3JE5fnoGIJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import Trainer, TrainingArguments\n","\n","\n","peft_model = get_peft_model(model, lora_config)\n","peft_model.print_trainable_parameters()\n","\n","train_dataset = tamil_0_tokenized\n","val_dataset = tamil_1_tokenized\n","\n","\n","def compute_metrics(eval_pred):\n","    logits, labels = eval_pred\n","    predictions = torch.argmax(torch.tensor(logits), dim=1)\n","\n","    acc = accuracy_score(labels, predictions)\n","    f1 = f1_score(labels, predictions, average=\"macro\")  # Macro F1 handles class imbalance\n","\n","    return {\"accuracy\": acc, \"f1_score\": f1}\n","\n","\n","class CustomTrainer(Trainer):\n","  def __init__(self, gamma=2.0, *args, **kwargs):\n","    super().__init__(*args, **kwargs)\n","    self.gamma = gamma\n","\n","  def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n","      labels = inputs.pop(\"labels\")\n","      outputs = model(**inputs)\n","      logits = outputs.logits\n","      loss = loss_fn(logits, labels)\n","      return (loss, outputs) if return_outputs else loss\n","\n","# Training Arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./results\",\n","    learning_rate=1e-4,  # Increase learning rate\n","    num_train_epochs=10,  # Increase epochs\n","    per_device_train_batch_size=64,  # Try larger batch\n","    weight_decay=0.01,\n","    evaluation_strategy=\"epoch\",\n","    save_strategy=\"epoch\",\n","    load_best_model_at_end=True,\n",")\n","\n","# Use the Custom Trainer\n","trainer = CustomTrainer(\n","    model=peft_model,\n","    args=training_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=val_dataset,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n","    gamma=3.0\n",")\n","\n","# Train the model\n","trainer.train()\n","\n","# Save the model\n","trainer.save_model(\"./tamil-comment-classifier\")\n","\n","# Function for inference\n","def classify_comment(text):\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n","    inputs = {key: value.to(device) for key, value in inputs.items()}\n","    model.eval()\n","    with torch.no_grad():\n","        outputs = peft_model(**inputs)\n","\n","        logits = outputs.logits\n","        predicted_class = torch.argmax(logits, dim=1).item()\n","    return \"Offensive\" if predicted_class == 1 else \"Not Offensive\"\n","\n","# Test with a sample comment\n","sample_comment = \"இது ஒரு நல்ல பதிவு\"\n","prediction = classify_comment(sample_comment)\n","print(f\"Comment: {sample_comment}\")\n","print(f\"Prediction: {prediction}\")\n","\n"],"metadata":{"id":"VNeuRtFg-9ij","colab":{"base_uri":"https://localhost:8080/","height":280},"outputId":"3d8878b3-9e18-46c6-a26d-9f3e2e33d7b6","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["trainable params: 886,274 || all params: 238,444,036 || trainable%: 0.3717\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n","  warnings.warn(\n","<ipython-input-39-398e2bba2829>:23: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainer.__init__`. Use `processing_class` instead.\n","  super().__init__(*args, **kwargs)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4276' max='26540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 4276/26540 35:49 < 3:06:38, 1.99 it/s, Epoch 3.22/20]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>F1 Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.062500</td>\n","      <td>0.059650</td>\n","      <td>0.774717</td>\n","      <td>0.737733</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.052600</td>\n","      <td>0.062587</td>\n","      <td>0.778447</td>\n","      <td>0.744477</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.047500</td>\n","      <td>0.053305</td>\n","      <td>0.814034</td>\n","      <td>0.769796</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"Ie6OdmpGs0J4"},"execution_count":null,"outputs":[]}]}
